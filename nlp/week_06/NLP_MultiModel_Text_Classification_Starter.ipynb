{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2051cc4a",
   "metadata": {},
   "source": [
    "\n",
    "#  Applying Machine Learning Models to Text Data\n",
    "### Starter Notebook for NLP & Machine Learning Lab\n",
    "\n",
    "In this lab, you'll learn how to:\n",
    "1. Convert text into numerical features using vectorization.\n",
    "2. Train and evaluate multiple ML models on text data.\n",
    "3. Compare results across **MultinomialNB**, **DecisionTree**, **RandomForest**, and a simple **Neural Network**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69493cef",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4abcf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2338\n",
      "Example text:\n",
      " Apparently, my editor didn't do what I wanted it to do, so I'll try again.\n",
      "\n",
      "i'm looking for any programs or code to do simple animation and/or\n",
      "drawing using fractals in TurboPascal for an IBM\n",
      "              Thanks in advance\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "categories = ['rec.sport.baseball', 'sci.space', 'talk.politics.mideast', 'comp.graphics']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Number of samples:\", len(X))\n",
    "print(\"Example text:\\n\", X[0][:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f90637",
   "metadata": {},
   "source": [
    "## Step 2: Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff49c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer shape: (2338, 3000)\n",
      "TF-IDF Vectorizer shape: (2338, 3000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=3000)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "X_train_count, X_test_count, y_train, y_test = train_test_split(X_count, y, test_size=0.2, random_state=42)\n",
    "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Count Vectorizer shape:\", X_count.shape)\n",
    "print(\"TF-IDF Vectorizer shape:\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe278c7",
   "metadata": {},
   "source": [
    "## Step 3: Model 1 — Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3cbbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.8825\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       132\n",
      "           1       0.90      0.86      0.88       118\n",
      "           2       0.78      0.91      0.84       111\n",
      "           3       0.96      0.82      0.88       107\n",
      "\n",
      "    accuracy                           0.88       468\n",
      "   macro avg       0.89      0.88      0.88       468\n",
      "weighted avg       0.89      0.88      0.88       468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = mnb.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Naïve Bayes Accuracy:\", round(accuracy_score(y_test, y_pred_nb), 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e6acb",
   "metadata": {},
   "source": [
    "## Step 4: Model 2 — Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cda1ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "dt.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", round(accuracy_score(y_test, y_pred_dt), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467b5ae",
   "metadata": {},
   "source": [
    "## Step 5: Model 3 — Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca45fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", round(accuracy_score(y_test, y_pred_rf), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67daf14",
   "metadata": {},
   "source": [
    "## Step 6: Model 4 — Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66341a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rewheaton/Code/rewheaton.github.io/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4742 - loss: 1.3337 - val_accuracy: 0.6845 - val_loss: 1.1961\n",
      "Epoch 2/3\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7641 - loss: 0.9639 - val_accuracy: 0.8717 - val_loss: 0.6864\n",
      "Epoch 3/3\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.4606 - val_accuracy: 0.9091 - val_loss: 0.3881\n",
      "Neural Network Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_dense = X_train_tfidf.toarray()\n",
    "X_test_dense = X_test_tfidf.toarray()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_dense, y_train, epochs=3, batch_size=64, validation_split=0.1, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(X_test_dense, y_test, verbose=0)\n",
    "print(f\"Neural Network Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb617dbc",
   "metadata": {},
   "source": [
    "## Step 7: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffd0b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.882479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NeuralNetwork</th>\n",
       "      <td>0.878205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.822650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.632479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy\n",
       "MultinomialNB  0.882479\n",
       "NeuralNetwork  0.878205\n",
       "RandomForest   0.822650\n",
       "DecisionTree   0.632479"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = {\n",
    "    \"MultinomialNB\": accuracy_score(y_test, y_pred_nb),\n",
    "    \"DecisionTree\": accuracy_score(y_test, y_pred_dt),\n",
    "    \"RandomForest\": accuracy_score(y_test, y_pred_rf),\n",
    "    \"NeuralNetwork\": test_acc\n",
    "}\n",
    "pd.DataFrame(results, index=[\"Accuracy\"]).T.sort_values(\"Accuracy\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e29ec0",
   "metadata": {},
   "source": [
    "\n",
    "## Step 8: Reflection & Discussion\n",
    "\n",
    "**Discussion Prompts:**\n",
    "- Which model performed best and why?\n",
    "- Which model trained the fastest?\n",
    "- How do vectorization and model type influence performance?\n",
    "- When might you prefer a simple model like Naïve Bayes over a neural network?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa307c",
   "metadata": {},
   "source": [
    "# How do vectorization and model type influence performance?\n",
    "\n",
    "In text classification, **the features you feed the model (vectorization)** and **the model family** interact tightly. Here’s how they influence performance—and how to pair them well.\n",
    "\n",
    "## Vectorization → what the model “sees”\n",
    "\n",
    "* **Bag-of-Words (counts)**: very sparse, high-dimensional; captures word presence/frequency but little order/semantics. Strong signal for topical data.\n",
    "* **TF-IDF**: reweights counts to downplay common words; usually +1–3 F1 over raw counts. Key knobs: `min_df`, `max_df`, `sublinear_tf=True`, `ngram_range=(1,2)`, **L2-normalize**.\n",
    "* **Character n-grams**: robust to typos, morphology, and domain codes; great for noisy text, names, product IDs.\n",
    "* **Static word embeddings** (Word2Vec/GloVe; averaged): dense, low-dimensional; adds semantics but loses precise token cues; helps when docs are short.\n",
    "* **Contextual embeddings** (BERT/DistilBERT): dense, context-aware; best raw accuracy/F1, higher compute.\n",
    "\n",
    "## Model type → how it uses those features\n",
    "\n",
    "* **Multinomial Naive Bayes (MNB)**: excels on **counts/TF-IDF** (especially unigram/bigram); fast, robust on sparse text; can underfit nuanced classes. Tune `alpha`.\n",
    "* **Linear classifiers** (LogReg, Linear SVM): top performers on **TF-IDF/char n-grams**; scale to huge vocabularies; tune regularization (`C`) and class weights.\n",
    "* **k-NN**: can work with **TF-IDF + cosine**; inference slow; sensitive to scaling/sparsity.\n",
    "* **Trees/Random Forest/GBMs**: often mediocre on raw sparse TF-IDF (split criteria don’t love ultra-sparse, wide features). Better after **dense embeddings** or strong feature selection.\n",
    "* **Neural nets (MLP/CNN/RNN)**: prefer **dense embeddings**; with enough data, can beat linear models; need regularization and tuning.\n",
    "* **Transformers**: use **contextual embeddings** end-to-end; usually best, with higher training/inference cost.\n",
    "\n",
    "## Good pairings (rule-of-thumb)\n",
    "\n",
    "* **TF-IDF (1–2 grams)** → **MNB / Linear SVM / Logistic Regression** ✅\n",
    "* **Char n-grams** → **Linear SVM / LogReg** (robust to noise) ✅\n",
    "* **Averaged static embeddings** → **LogReg / MLP** ✅\n",
    "* **Contextual embeddings (BERT)** → **Linear head or fine-tuned transformer** ✅\n",
    "* **Raw TF-IDF** → **Trees/RF/GBM** ❌ (usually underperform unless heavily reduced)\n",
    "\n",
    "## How choices shift bias/variance & compute\n",
    "\n",
    "* Higher n-grams and larger vocabularies ↓bias but ↑variance/overfit and memory. Use `min_df`, `max_df`, and regularization.\n",
    "* Dense embeddings reduce dimensionality (↓variance) and add semantics (↓bias), often improving minority-class recall.\n",
    "* Linear models on TF-IDF train fast and are strong baselines; transformers improve hardest confusions at higher cost.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f25543",
   "metadata": {},
   "source": [
    "# When might you prefer a simple model like Naïve Bayes over a neural network?\n",
    "**Naïve Bayes (NB)** over a neural net when you need **speed, simplicity, and strong performance on sparse text** without heavy compute or tuning:\n",
    "\n",
    "**When NB is a better choice**\n",
    "\n",
    "* **Small datasets / few labels:** NB learns good priors from limited data; NNs often overfit or need augmentation.\n",
    "* **High-dimensional, sparse features (TF-IDF, bag-of-words, char n-grams):** NB is a natural fit and often very competitive.\n",
    "* **Tight compute/latency budgets:** Trains in seconds, tiny memory/CPU footprint, great for on-device or serverless.\n",
    "* **Rapid baselines & sanity checks:** Gives a strong, reliable benchmark fast; useful in model selection loops.\n",
    "* **Stable, low-maintenance deployment:** Few hyperparameters, deterministic, easy to port (even to SQL/UDFs).\n",
    "* **Streaming/online updates:** `partial_fit` lets you update with new batches without full retraining.\n",
    "* **Interpretability:** Per-class log probabilities reveal which tokens drive decisions—handy for audits and feature hygiene.\n",
    "* **Noisy text tasks:** Spam filtering, topic routing, language ID—NB is robust to lots of irrelevant features.\n",
    "* **Typical wins**\n",
    "\n",
    "* Email/SMS **spam detection**\n",
    "* News/forum **topic classification**\n",
    "* **Document routing** and tag suggestion\n",
    "* **Language detection** and simple sentiment with clear cues\n",
    "\n",
    "**When not to use NB**\n",
    "\n",
    "* You need **long-range context/semantics** (sarcasm, coreference, subtle sentiment).\n",
    "* You have **plenty of data/compute** and the task benefits from context (where transformers shine).\n",
    "\n",
    "**Rule of Thumb**\n",
    "* Start with TF-IDF (1–2 grams) + NB for a fast, strong baseline. If errors cluster around semantic nuance or long context, step up to a linear model or a small transformer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
